# ğŸš€ Environnement de Tests de Performance - Unify App

## ğŸ“‹ Table des matiÃ¨res
1. [Vue d'ensemble](#vue-densemble)
2. [PrÃ©requis](#prÃ©requis)
3. [Installation](#installation)
4. [Versions & ReproductibilitÃ©](#versions--reproductibilitÃ©)
5. [DonnÃ©es de test](#donnÃ©es-de-test)
6. [Lancement de l'environnement](#lancement-de-lenvironnement)
7. [ExÃ©cution des tests](#exÃ©cution-des-tests)
8. [Analyse des rÃ©sultats](#analyse-des-rÃ©sultats)

---

## ğŸ¯ Vue d'ensemble

Environnement complet pour tester les performances de l'API Unify avec :
- **Prometheus** : Collecte de mÃ©triques
- **Grafana** : Visualisation des mÃ©triques
- **k6** : Tests de charge
- **Seed de donnÃ©es** : Environnement reproductible

---

## ğŸ“¦ PrÃ©requis

- **Docker** et **Docker Compose** installÃ©s
- **Node.js** 16+ 
- **Git**
- AccÃ¨s Ã  Supabase (URL + API Key)

---

## ğŸ”§ Installation

```bash
# Installer les dÃ©pendances k6
cd perf-testing
npm install

# OU installer k6 globalement (Windows)
choco install k6

# Linux/Mac
brew install k6
```

---

## ğŸ“Œ Versions & ReproductibilitÃ©

### Tags Git

**Version baseline (avant optimisations) :**
```bash
git tag perf-baseline 3beac72
git push origin perf-baseline
```

**Version aprÃ¨s optimisations :**
```bash
# AprÃ¨s avoir fait vos optimisations
git tag perf-after <commit-hash>
git push origin perf-after
```

### Basculer entre versions

```bash
# Tester la baseline
git checkout perf-baseline
npm run perf:baseline

# Tester aprÃ¨s optimisations
git checkout perf-after
npm run perf:after

# Comparer les rÃ©sultats
npm run perf:compare
```

---

## ğŸ—„ï¸ DonnÃ©es de test

### Seed automatique

Le script `seed-database.js` crÃ©e un jeu de donnÃ©es reproductible :

- **100 utilisateurs** avec positions gÃ©ographiques (Paris, Lyon, Marseille, etc.)
- **300 activitÃ©s** de course Ã  pied avec statistiques
- **50 runners actifs** sur la carte
- **200 relations/contacts** entre utilisateurs

### Lancer le seed

```bash
npm run seed
```

### Variables du seed

Modifiez `seed-config.json` pour ajuster :
- Nombre d'utilisateurs
- Zones gÃ©ographiques
- DensitÃ© d'activitÃ©s

---

## ğŸ³ Lancement de l'environnement

### Configuration des variables

Copiez et Ã©ditez `.env.perf` :

```bash
cp .env.perf.example .env.perf
```

Variables requises :
```env
SUPABASE_URL=https://muhexuopzmqdxonurktn.supabase.co
SUPABASE_API_KEY=votre_clÃ©_api
SUPABASE_SERVICE_KEY=votre_service_key
APP_PORT=3000
PROMETHEUS_PORT=9090
GRAFANA_PORT=3001
```

### DÃ©marrer tout l'environnement

```bash
# DÃ©marrer Prometheus + Grafana + Exporteur de mÃ©triques
npm run perf:start

# OU avec Docker Compose directement
docker-compose up -d
```

### Services disponibles

| Service | URL | Credentials |
|---------|-----|-------------|
| **App Metrics** | http://localhost:3000/metrics | - |
| **Prometheus** | http://localhost:9090 | - |
| **Grafana** | http://localhost:3001 | admin / admin |

---

## ğŸ§ª ExÃ©cution des tests

### Test de charge complet

```bash
# Test de charge standard (50 VUs pendant 2 minutes)
npm run test:load

# Test de stress (augmentation progressive jusqu'Ã  200 VUs)
npm run test:stress

# Test de spike (pics soudains de trafic)
npm run test:spike

# Test d'endurance (charge stable pendant 30 minutes)
npm run test:soak
```

### Test d'un endpoint spÃ©cifique

```bash
# Tester getNearbyRunners
npm run test:nearby-runners

# Tester getActivities
npm run test:activities

# Tester les messages
npm run test:messages
```

### Tests avec seuils SLO

```bash
# ExÃ©cuter les tests avec validation des SLOs
npm run test:slo
```

---

## ğŸ“Š Analyse des rÃ©sultats

### MÃ©triques collectÃ©es

**SLI Latence :**
- p50 (mÃ©diane)
- p95 (95e percentile) â† **UtilisÃ© pour SLO**
- p99 (99e percentile)

**SLI Erreurs :**
- Taux d'erreurs 4xx (client)
- Taux d'erreurs 5xx (serveur) â† **UtilisÃ© pour SLO**

**Autres mÃ©triques :**
- Throughput (requÃªtes/seconde)
- Temps de rÃ©ponse moyen
- Nombre de connexions actives

### Consulter les rÃ©sultats

#### 1. Dans le terminal (k6)

Les rÃ©sultats s'affichent automatiquement aprÃ¨s chaque test :

```
âœ“ status is 200
âœ“ latency is below 600ms
âœ“ error rate is below 5%

checks.........................: 100.00% âœ“ 15000  âœ— 0
http_req_duration..............: avg=185ms p95=350ms
http_reqs......................: 5000    83.33/s
```

#### 2. Dans Grafana

1. Ouvrir http://localhost:3001
2. Login: `admin` / `admin`
3. Dashboard **"Unify Performance"** prÃ©configurÃ© avec :
   - Graphiques de latence
   - Taux d'erreur
   - DÃ©bit (throughput)
   - Comparaison baseline vs after

#### 3. Dans Prometheus

1. Ouvrir http://localhost:9090
2. RequÃªtes PromQL utiles :

```promql
# Latence p95 par endpoint
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint))

# Taux d'erreur 5xx
sum(rate(http_requests_total{status_code=~"5.."}[5m])) / sum(rate(http_requests_total[5m]))

# Nombre de requÃªtes par seconde
rate(http_requests_total[1m])
```

### Exporter les rÃ©sultats

```bash
# Exporter en JSON
npm run test:load -- --out json=results/baseline.json

# Exporter en CSV
npm run test:load -- --out csv=results/baseline.csv

# Exporter vers InfluxDB
npm run test:load -- --out influxdb=http://localhost:8086/k6
```

---

## ğŸ“ˆ Tableau SLO de rÃ©fÃ©rence

| Endpoint | Seuil Latence p95 | Seuil Erreurs 5xx |
|----------|-------------------|-------------------|
| `GET /api/users` | 300ms | < 3% |
| `GET /api/runners` | 300ms | < 3% |
| `getNearbyRunners` | 600ms | < 5% |
| `GET /api/activities` | 400ms | < 3% |
| `GET /api/messages` | 400ms | < 3% |

---

## ğŸ”„ Infrastructure

### Configuration locale

- **CPU** : 4 cores recommandÃ©s
- **RAM** : 8GB minimum
- **Instances** : 1 (mode dÃ©veloppement)
- **Pool DB** : Supabase gÃ©rÃ© (pooling automatique)

### Configuration staging

```yaml
# staging-config.yml
app:
  instances: 2
  cpu: 2
  memory: 4GB

database:
  pool_size: 20
  max_connections: 100

load_balancer:
  enabled: true
  algorithm: round-robin
```

---

## ğŸš€ Commandes rapides

```bash
# Setup complet
npm run setup

# Seed + Tests complets
npm run perf:full

# Nettoyer l'environnement
npm run perf:clean

# Voir les logs Prometheus
docker-compose logs -f prometheus

# Voir les logs Grafana
docker-compose logs -f grafana

# ArrÃªter tout
npm run perf:stop
```

---

## ğŸ“ Notes importantes

1. **Seed avant chaque test** : Pour des rÃ©sultats reproductibles
2. **MÃªme infrastructure** : Utilisez toujours le mÃªme environnement
3. **Horaires** : Testez aux mÃªmes heures (Ã©viter les heures de pointe de Supabase)
4. **Cache** : Videz les caches entre baseline et after
5. **Versions** : Documentez les versions de toutes les dÃ©pendances

---

## ğŸ› Troubleshooting

### Prometheus ne dÃ©marre pas
```bash
docker-compose down -v
docker-compose up -d
```

### k6 n'exÃ©cute pas les tests
```bash
# VÃ©rifier l'installation
k6 version

# RÃ©installer si besoin
npm install -g k6
```

### Grafana ne se connecte pas Ã  Prometheus
```bash
# VÃ©rifier le rÃ©seau Docker
docker network ls
docker network inspect perf-testing_default
```

---

## ğŸ“š Ressources

- [Documentation k6](https://k6.io/docs/)
- [Prometheus](https://prometheus.io/docs/)
- [Grafana](https://grafana.com/docs/)
- [Supabase Performance](https://supabase.com/docs/guides/platform/performance)

---

**CrÃ©Ã© le** : 2025-11-07  
**Commit baseline** : 3beac72  
**Auteur** : Ã‰quipe Unify

